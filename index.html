


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 80px;
    height: 80px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 100px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Abhishek Gupta</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="67%" valign="middle">
            <p align="center">
              <name>AbhishekGupta</name>
            </p>
            <p>
            I am currently a post-doctoral researcher at MIT, and an affiliate assistant professor in computer science at the Paul G. Allen School at the University of Washington. I will join the department as an assistant professor in Fall 2022. At MIT, I am collaborating with Professor Russ Tedrake and Professor Pulkit Agarwal. I am currently looking for highly motivated students interested in pushing the frontier robotics and machine learning problems to work with me at UW. Please apply directly through the UW admissions <a href="https://www.cs.washington.edu/academics/phd/admissions">portal</a>, and drop me a line to look through your application. 
            </p>

            <p>
            I did my PhD in machine learning and robotics at <a href=http://bair.berkeley.edu>BAIR</a> at UC Berkeley, where I was advised by <a href=https://people.eecs.berkeley.edu/~svlevine/>Professor Sergey Levine</a> and <a href=http://www.cs.berkeley.edu/~pabbeel/>Professor Pieter Abbeel</a> and funded by the <a href=http://www.nsfgrfp.org/>NSF GRFP</a>. In a previous life, I completed my bachelors degrgee at <a href=http://www.eecs.berkeley.edu/>UC Berkeley</a>. 
            </p>

            <p>
            My main research goal is to develop algorithms which enable robotic systems to learn how to perform complex tasks in a variety of unstructured environments. To that end, I work towards building deep reinforcement learning algorithms that can learn in the real world. Recently, I have been specifically focusing on the problems of reward specification, continual real world data collection and learning, offline reinforcement learning for robotics and multi-task learning and dexterous manipulation with robotic hands.
            </p>

            <p align=center>
              <a href="mailto:abhigupta@eecs.berkeley.edu">Email</a> &nbsp/&nbsp
              <a href="files/cv.pdf">CV</a> &nbsp/&nbsp
              <a href="https://github.com/abhishekunique"> GitHub </a> &nbsp/&nbsp
              <a href="https://scholar.google.com/citations?hl=en&user=1wLVDP4AAAAJ">Google Scholar</a>
            </p>
          </td>
          <td width="40%">
            <img src="images/ta-abhishek.jpg" width="200">
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Workshop Papers and Pre-prints</heading>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


             <tr >
          <td width="15%">
            <div class="one">
                <img src='images/relmm.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2107.13545.pdf">
        <papertitle>Fully Autonomous Real-World Reinforcement Learning for Mobile Manipulation</papertitle></a><br>Charles Sun, JÄ™drzej Orbik, Coline Devin, Brian Yang, Abhishek Gupta, Glen Berseth, Sergey Levine<br>
                <em>arXiv preprint</em><br>
                <a href ="https://arxiv.org/abs/2107.13545?context=cs.RO">paper</a>
              </a></p>
              </td>
            </tr>


            
          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/ARM.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2007.02931.pdf">
        <papertitle>Adaptive risk minimization: A meta-learning approach for tackling group shift</papertitle></a><br>
Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, Chelsea Finn<br>
                <em>arXiv</em><br>
                <a href ="https://arxiv.org/abs/2007.02931">paper</a>
    /
    <a href ="https://bair.berkeley.edu/blog/2020/11/05/arm/">blog</a>
              </a></p>
              </td>
            </tr>
            

                 <tr >
          <td width="15%">
            <div class="one">
                <img src='images/ecological.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2006.12478.pdf">
        <papertitle>Ecological Reinforcement Learning</papertitle></a><br>
John D Co-Reyes, Suvansh Sanjeev, Glen Berseth, Abhishek Gupta, Sergey Levine<br>
                <em>arXiv Preprint</em><br>
                <a href ="https://arxiv.org/abs/2006.12478">paper</a>
              </a></p>
              </td>
            </tr>
            


          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/MI.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2106.07278.pdf">
        <papertitle>Which Mutual-Information Representation Learning Objectives are Sufficient for Control?</papertitle></a><br>
Gregory Kahn, Pieter Abbeel, Sergey Levine<br>
                <em>arXiv preprint</em><br>
                <a href ="https://arxiv.org/abs/2106.07278">paper</a>
              </a></p>
              </td>
            </tr>

                               <tr >
          <td width="15%">
            <div class="one">
                <img src='images/unsupMRL.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1806.04640.pdf">
        <papertitle>Unsupervised meta-learning for reinforcement learning</papertitle></a><br>
Abhishek Gupta*, Benjamin Eysenbach*, Chelsea Finn, Sergey Levine<br>
                <em>arXiv preprint</em><br>
    <a href="https://arxiv.org/abs/1806.04640">paper</a>
    /
        <a href="https://bair.berkeley.edu/blog/2020/05/01/umrl/">blog</a>

              </a></p>
              </td>
            </tr>



          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/awac.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2006.09359.pdf">
        <papertitle>Accelerating online reinforcement learning with offline datasets</papertitle></a><br>
      Ashvin Nair*, Abhishek Gupta*, Murtaza Dalal, Sergey Levine<br>
      <em>arXiv preprint</em><br>
        <a href="https://arxiv.org/abs/2006.09359">paper</a>
              </a></p>
              </td>
            </tr>

      </table>




      <br>
      <br>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Publications</heading>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            
              <tr >
          <td width="15%">
            <div class="one">
                <img src='images/mural_overview.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2107.07184.pdf">
        <papertitle>MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning</papertitle></a><br>Kevin Li*, Abhishek Gupta*, Ashwin D Reddy, Vitchyr Pong, Aurick Zhou, Justin Yu, Sergey Levine<br>
                <em>ICML 2021</em><br>
                <a href ="https://arxiv.org/abs/2107.07184">paper</a>
    /
    <a href="https://sites.google.com/view/mural-rl">website</a>
              </a></p>
              </td>
            </tr>
            
            
          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/sawyer_noString.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2012.09812.pdf">
        <papertitle>Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention</papertitle></a><br>Abhishek Gupta*, Justin Yu*, Tony Z. Zhao*, Vikash Kumar*, Aaron Rovinsky, Kelvin Xu, Thomas Devlin, Sergey Levine<br>
                <em>ICRA 2021</em><br>
                <a href ="https://arxiv.org/abs/2104.11203">paper</a>
                  /
                  <a href="https://sites.google.com/view/mtrf">website</a>
              </a></p>
              </td>
            </tr>
            



          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/robel.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1909.11639.pdf">
        <papertitle>ROBEL: RObotics BEnchmarks for Learning with low-cost robots</papertitle></a><br>
Michael Ahn, Henry Zhu, Kristian Hartikainen, Hugo Ponte, Abhishek Gupta, Sergey Levine, Vikash Kumar<br>
                <em>CoRL 2019</em><br>
                <a href ="https://arxiv.org/abs/1909.11639">paper</a>
                /
                <a href="https://ai.googleblog.com/2019/10/robel-robotics-benchmarks-for-learning.html">blog</a>
              </a></p>
              </td>
            </tr>
            
          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/r3l.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2004.12570.pdf">
        <papertitle>The ingredients of real-world robotic reinforcement learning</papertitle></a><br>
Henry Zhu*, Justin Yu*, Abhishek Gupta*, Dhruv Shah, Kristian Hartikainen, Avi Singh, Vikash Kumar, Sergey Levine<br>
                <em>ICLR 2020</em><br>
                <a href ="https://arxiv.org/abs/2004.12570">paper</a>
                /
                <a href ="https://bair.berkeley.edu/blog/2020/04/27/ingredients/">blog</a>

              </a></p>
              </td>
            </tr>


          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/discor.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2003.07305.pdf">
        <papertitle>Discor: Corrective feedback in reinforcement learning via distribution correction</papertitle></a><br>
Aviral Kumar, Abhishek Gupta, Sergey Levine<br>
                <em>NeurIPS 2020</em><br>
                <a href ="https://arxiv.org/abs/2003.07305">paper</a>
                /
                <a href="https://bair.berkeley.edu/blog/2020/03/16/discor/">blo</a>
              </a></p>
              </td>
            </tr>


          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/pcgrad.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/2001.06782.pdf">
        <papertitle>Gradient surgery for multi-task learning</papertitle></a><br>
Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, Chelsea Finn<br>
                <em>NeurIPS 2020</em><br>
                <a href ="https://arxiv.org/abs/2001.06782">paper</a>
              </a></p>
              </td>
            </tr>
            
            
          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/GCSL.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1912.06088.pdf">
        <papertitle>Learning to reach goals via iterated supervised learning</papertitle></a><br>
Dibya Ghosh*, Abhishek Gupta*, Ashwin Reddy, Justin Fu, Coline Devin, Benjamin Eysenbach, Sergey Levine<br>
                <em>ICLR 2021</em><br>
                <a href ="https://arxiv.org/abs/1912.06088">paper</a>
                /
                <a href="https://bair.berkeley.edu/blog/2020/10/13/supervised-rl/">blog</a>
              </a></p>
              </td>
            </tr>

          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/vizdoom_first.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1912.04226.pdf">
        <papertitle>Unsupervised curricula for visual meta-reinforcement learning</papertitle></a><br>
Allan Jabri, Kyle Hsu, Benjamin Eysenbach, Abhishek Gupta, Alexei Efros, Sergey Levine, Chelsea Finn<br>
                <em>NeurIPS 2019</em><br>
                <a href ="https://arxiv.org/abs/1912.04226">paper</a>
              </a></p>
              </td>
            </tr>
            
            
            
          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/rpl.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1910.11956.pdf">
        <papertitle>Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning</papertitle></a><br>
Abhishek Gupta, Vikash Kumar, Corey Lynch, Sergey Levine, Karol Hausman<br>
                <em>CORL 2019</em><br>
                <a href ="https://arxiv.org/abs/1910.11956">paper</a>
    /
    <a href="https://relay-policy-learning.github.io/">website</a>
              </a></p>
              </td>
            </tr>
            
            
          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/giulia.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1905.12621.pdf">
        <papertitle>Learning latent state representation for speeding up exploration</papertitle></a><br>
Giulia Vezzani, Abhishek Gupta, Lorenzo Natale, Pieter Abbeel<br>
                <em>arXiv</em><br>
                <a href ="https://arxiv.org/abs/1905.12621">paper</a>
              </a></p>
              </td>
            </tr>
            

          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/gmps.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1904.00956.pdf">
        <papertitle>Guided meta-policy search</papertitle></a><br>
Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey Levine, Chelsea Finn<br>
                <em>NeurIPS 2019</em><br>
                <a href ="https://arxiv.org/abs/1904.00956">paper</a>
              </a></p>
              </td>
            </tr>
            
          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/hand_real.jpg' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/abs/1810.06045.pdf">
        <papertitle>Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost</papertitle></a><br>
Henry Zhu*, Abhishek Gupta*, Aravind Rajeswaran, Sergey Levine, Vikash Kumar<br>
                <em>ICRA 2019</em><br>
                <a href="https://arxiv.org/abs/1810.06045">paper</a>
                /
                <a href="https://bair.berkeley.edu/blog/2018/08/31/dexterous-manip/">blog</a>

              </a></p>
              </td>
            </tr>

            
        <tr >
          <td width="15%">
            <div class="one">
                <img src='images/LGPL.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1811.07882.pdf">
        <papertitle>Guiding policies with language via meta-learning</papertitle></a><br>
John D Co-Reyes, Abhishek Gupta, Suvansh Sanjeev, Nick Altieri, John DeNero, Pieter Abbeel, Sergey Levine<br>
                <em>ICLR 2019</em><br>
                <a href="https://arxiv.org/abs/1811.07882">paper</a>
              </a></p>
              </td>
            </tr>
         
         
                   <tr >
          <td width="15%">
            <div class="one">
                <img src='images/ARC.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1811.07819.pdf">
        <papertitle>Learning actionable representations with goal-conditioned policies</papertitle></a><br>
Dibya Ghosh, Abhishek Gupta, Sergey Levine<br>
                <em>ICLR 2019</em><br>
    <a href="https://arxiv.org/abs/1811.07819">paper</a>
              </a></p>
              </td>
            </tr>

                            <tr >
          <td width="15%">
            <div class="one">
                <img src='images/CRL.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/abs/1807.04640.pdf">
        <papertitle>Automatically composing representation transformations as a means for generalization</papertitle></a><br>
Michael B. Chang, Abhishek Gupta, Sergey Levine, Thomas Griffith<br>
                <em>ICLR 2019</em><br>
    <a href="https://arxiv.org/abs/1807.04640">paper</a>
              </a></p>
              </td>
            </tr>


                               <tr >
          <td width="15%">
            <div class="one">
                <img src='images/sectar_model.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1806.02813.pdf">
        <papertitle>Self-consistent trajectory autoencoder: Hierarchical reinforcement learning with trajectory embeddings</papertitle></a><br>
John D Co-Reyes*, YuXuan Liu*, Abhishek Gupta*, Benjamin Eysenbach, Pieter Abbeel, Sergey Levine<br>
                <em>ICML 2018</em><br>
    <a href="https://arxiv.org/abs/1806.02813">paper</a>
              </a></p>
              </td>
            </tr>


                               <tr >
          <td width="15%">
            <div class="one">
                <img src='images/imitation.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1707.03374.pdf">
        <papertitle>Imitation from observation: Learning to imitate behaviors from raw video via context translation</papertitle></a><br>
YuXuan Liu*, Abhishek Gupta*, Pieter Abbeel, Sergey Levine<br>
                <em>ICRA 2018</em><br>
    <a href="https://arxiv.org/abs/1707.03374">paper</a>
    /
    <a href="https://www.youtube.com/watch?v=CNr5T2vTX_I">video</a>

              </a></p>
              </td>
            </tr>

                               <tr >
          <td width="15%">
            <div class="one">
                <img src='images/metaexplore.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1802.07245.pdf">
        <papertitle>Meta-reinforcement learning of structured exploration strategies</papertitle></a><br>
Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, Sergey Levine<br>
                <em>NeurIPS 2018</em><br>
    <a href="https://arxiv.org/abs/1802.07245">paper</a>
    /
    <a href="https://github.com/russellmendonca/maesn_suite">code</a>
              </p>
              </td>
            </tr>

        <tr >
          <td width="15%">
            <div class="one">
                <img src='images/diversity.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/abs/1802.06070">
        <papertitle>Diversity is all you need: Learning skills without a reward function</papertitle></a><br>
Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, Sergey Levine<br>
                <em>ICLR 2019</em><br>
    <a href="https://arxiv.org/abs/1802.06070">paper</a>
    /
    <a href="https://sites.google.com/view/diayn">video</a>

              </a></p>
              </td>
            </tr>
         

        <tr >
          <td width="15%">
            <div class="one">
                <img src='images/hand_demo.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/abs/1709.10087">
        <papertitle>Learning complex dexterous manipulation with deep reinforcement learning and demonstrations</papertitle></a><br>
Aravind Rajeswaran*, Vikash Kumar*, Abhishek Gupta, Giulia Vezzanni, John Schulman, Emanuel Todorov, Sergey Levine<br>
                <em>RSS 2018</em><br>
    <a href="https://arxiv.org/abs/1709.10087">paper</a>
    /
    <a href="https://www.youtube.com/watch?v=jJtBll8l_OM">video</a>
              </a></p>
              </td>
            </tr>

       <tr >
          <td width="15%">
            <div class="one">
                <img src='images/modular.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1609.07088v1.pdf">
        <papertitle>Learning modular neural network policies for multi-task and multi-robot transfer</papertitle></a><br>
Abhishek Gupta*, Coline Devin*, Trevor Darrell, Pieter Abbeel, Sergey Levine<br>
                <em>ICRA 2017</em><br>
      <a href="https://arxiv.org/abs/1609.07088">paper</a>
      /
      <a href="https://sites.google.com/site/modularpolicynetworks/">video</a>

    
              </p>
              </td>
            </tr>

          <tr >
          <td width="15%">
            <div class="one">
                <img src='images/subspace.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1703.02949.pdf">
        <papertitle>Learning invariant feature spaces to transfer skills with reinforcement learning</papertitle></a><br>
Abhishek Gupta*, Coline Devin*, Yuxuan Liu, Pieter Abbeel, Sergey Levine<br>
                <em>ICLR 2017</em><br>
    <a href="https://arxiv.org/pdf/1703.02949.pdf">paper</a> 
    /
    <a href="https://sites.google.com/site/invariantfeaturetransfer">video</a> 
                </p>
              </td>
            </tr>

            [<a href="https://arxiv.org/pdf/1703.02949.pdf" onClick="recordOutboundLink(this, 'Links', 'subspace_pdf');return false;">PDF</a>][<a href="https://sites.google.com/site/invariantfeaturetransfer/" onClick="recordOutboundLink(this, 'Links', 'subspace_web');return false;">Video</a>][<a href="https://openreview.net/forum?id=Hyq4yhile" onClick="recordOutboundLink(this, 'Links', 'subspace_arxiv');return false;">OpenReview</a>]


                               <tr >
          <td width="15%">
            <div class="one">
                <img src='images/softhand.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://arxiv.org/pdf/1603.06348v2.pdf">
        <papertitle>Learning dexterous manipulation for a soft robotic hand from human demonstrations</papertitle></a><br>
Abhishek Gupta, Clemens Eppner, Sergey Levine, Pieter Abbeel<br>
                <em>IROS 2016</em><br>
    <a href="https://arxiv.org/pdf/1603.06348v2.pdf">paper</a>
    /
    <a href="https://www.youtube.com/watch?v=XyZFkJWu0Q0">video</a>

              </a></p>
              </td>
            </tr>

        <tr >
          <td width="15%">
            <div class="one">
                <img src='images/rohantamp.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://people.eecs.berkeley.edu/~pabbeel/papers/2016-ICRA-tamp-learning.pdf">
        <papertitle>Guided search for task and motion plans using learned heuristics</papertitle></a><br>
Rohan Chitnis, Dylan Hadfield-Menell, Abhishek Gupta, Siddhart Srivastava, Edward Groshev, Christopher Lin, Pieter Abbeel<br>
                <em>ICRA 2016</em><br>
    <a href="https://people.eecs.berkeley.edu/~pabbeel/papers/2016-ICRA-tamp-learning.pdf">paper</a>
    /
    <a href="https://www.youtube.com/watch?v=Z0JFYUOdWis">video</a>

              </a></p>
              </td>
            </tr>

        <tr >
          <td width="15%">
            <div class="one">
                <img src='images/trajaware.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://people.eecs.berkeley.edu/~pabbeel/papers/2015-IROS-trajectory-aware-registration.pdf">
        <papertitle>Learning from multiple demonstrations using trajectory-aware non-rigid registration with applications to deformable object manipulation</papertitle></a><br>
Alex Lee, Abhishek Gupta, Henry Lu, Sergey Levine, Pieter Abbeel<br>
                <em>IROS 2015</em><br>
    <a href="https://people.eecs.berkeley.edu/~pabbeel/papers/2015-IROS-trajectory-aware-registration.pdf">paper</a>
              </a></p>
              </td>
            </tr>


                               <tr >
          <td width="15%">
            <div class="one">
                <img src='images/forcelfd.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://people.eecs.berkeley.edu/~pabbeel/papers/2015-ICRA-TPS-LfD-forces.pdf">
        <papertitle>Learning force-based manipulation of deformable objects from multiple demonstrations</papertitle></a><br>
Alex X. Lee, Henry Lu, Abhishek Gupta, Sergey Levine, Pieter Abbeel<br>
                <em>ICRA 2015</em><br>
    <a href="https://people.eecs.berkeley.edu/~pabbeel/papers/2015-ICRA-TPS-LfD-forces.pdf"">paper</a>
              </a></p>
              </td>
            </tr>

        <tr >
          <td width="15%">
            <div class="one">
                <img src='images/loops.png' width=130%>
            </div>
              </td>
              <td valign="top" width="85%">
              <p><a href="https://people.eecs.berkeley.edu/~pabbeel/papers/2015_AAAI_loops.pdf">
        <papertitle>Tractability of planning with loops</papertitle></a><br>
Siddharth Srivastava, Shlomo Zilberstein, Abhishek Gupta, Pieter Abbeel, Stuart Russell<br>
                <em>AAAI 2015</em><br>
                <a href ="https://people.eecs.berkeley.edu/~pabbeel/papers/2015_AAAI_loops.pdf">paper</a>
                  /
                  <a href="https://www.youtube.com/watch?v=N_co3vimPR4">video</a>
              </a></p>
              </td>
            </tr>


            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                <br>
                <p align="right"><font size="2">
                  Website template from <a href="http://www.cs.berkeley.edu/~barron/">Jon Barron</a>.
            <br>
            Last updated January 2021.
                  </font>
                </p>
                </td>
              </tr>
              </table>

      </table>

    </td>
    </tr>
  </table>


  </body>
</html>

